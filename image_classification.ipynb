{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projekt z przedmiotu Metody Klasyfikacji Danych Geoinformatycznych - Etap 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analiza/klasyfikacja dowolnych obrazów za pomocą macierzy wspólnych wystąpień (Grey Level Co-occurence Matrices - GLCM)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Skład zespołu: Marta Dzięgielewska s176363, Maciej Gielert s176137"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Link do etapu 1: https://docs.google.com/document/d/1HsTw6qhrXO0SoeWtg8hENvtkOi2oqkhV-VhOnhndA5s/edit?usp=sharing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Link do etapu 2: https://github.com/mdziegielewska/Image-Analysis-Classification-With-GLCM/blob/main/texture_analysis.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import skimage.transform\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from skimage.color import label2rgb\n",
    "from skimage.util import montage as montage2d\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataset do pobrania: https://www.robots.ox.ac.uk/~vgg/data/dtd/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 128\n",
    "\n",
    "# capture images and labels into arrays\n",
    "\n",
    "images = []\n",
    "labels = [] \n",
    "\n",
    "for directory_path in glob.glob(\"dtd/images/*/\"):\n",
    "    label = os.path.basename(os.path.dirname(directory_path))\n",
    "\n",
    "    for img_path in glob.glob(os.path.join(directory_path, \"*.jpg\")):\n",
    "        # reading images in grayscale\n",
    "        img = cv2.imread(img_path, 0)\n",
    "        img = cv2.resize(img, (SIZE, SIZE))\n",
    "\n",
    "        images.append(img)\n",
    "        labels.append(label)\n",
    "\n",
    "images = np.array(images)\n",
    "labels = np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_history = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode labels from text (folder names) to integers.\n",
    "\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "encoder.fit(labels)\n",
    "labels = encoder.transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test train split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "grayco_prop_list = ['contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation', 'ASM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extractor function\n",
    "\n",
    "def feature_extractor(dataset):\n",
    "    image_dataset = pd.DataFrame()\n",
    "\n",
    "    for image in range(dataset.shape[0]):\n",
    "        df = pd.DataFrame() \n",
    "        for angle in [0, np.pi/4, np.pi/2, 3*np.pi/4]:\n",
    "            for distance in [0,1,3,5]:\n",
    "                for greylevel in [256]:\n",
    "                \n",
    "                    img = dataset[image, :, :]\n",
    "                    #print(img.shape)\n",
    "\n",
    "                    # calculate glcm\n",
    "                    glcm = graycomatrix(img, distances=[distance], angles=[angle], levels=greylevel, symmetric=True, normed=True)\n",
    "\n",
    "                    for prop in grayco_prop_list: \n",
    "                        glcm_prop = graycoprops(glcm, prop)[0]\n",
    "                        df[f'{prop}{angle}{distance}{greylevel}'] = glcm_prop\n",
    "\n",
    "                    # append features from current image to the dataset\n",
    "        image_dataset = image_dataset.append(df)\n",
    "        \n",
    "    return image_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract features from training images\n",
    "\n",
    "image_features_train = feature_extractor(X_train)\n",
    "train_data = image_features_train.to_numpy()\n",
    "\n",
    "image_features_test = feature_extractor(X_test)\n",
    "test_data = image_features_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_features_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_features_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Wykonano trening na wszystkich cechach"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tocsvfile = image_features_train\n",
    "tocsvfile['labels'] = y_train.tolist()\n",
    "tocsvfile.to_csv('train.csv', index=False)\n",
    "\n",
    "tocsvfile = image_features_test\n",
    "tocsvfile['labels'] = y_test.tolist()\n",
    "tocsvfile.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "y_train = np.ravel(df_train.iloc[:,-1:].to_numpy())\n",
    "y_test = np.ravel(df_test.iloc[:,-1:].to_numpy())\n",
    "train_data = df_train[df_train.columns[:-1]]\n",
    "test_data = df_test[df_test.columns[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4512, 96)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2 = train_data\n",
    "X_test2 = test_data\n",
    "np.shape(test_data)\n",
    "np.shape(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = X_train2\n",
    "test_data = X_test2\n",
    "np.shape(test_data)\n",
    "np.shape(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MaciejGielerts176137\\miniconda3\\envs\\tfdml_plugin\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\MaciejGielerts176137\\miniconda3\\envs\\tfdml_plugin\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [ 0  1  2  4 24 25 26 28 48 49 50 52 72 73 74 76] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\MaciejGielerts176137\\miniconda3\\envs\\tfdml_plugin\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "sel = SelectKBest(f_classif, k=40).fit(X_train2, y_train)\n",
    "train_data = sel.transform(train_data)\n",
    "test_data = sel.transform(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1128, 40)\n",
      "(4512, 40)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(test_data))\n",
    "print(np.shape(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MaciejGielerts176137\\miniconda3\\envs\\tfdml_plugin\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.19326241134751773\n",
      "f1: 0.17373216039184866\n",
      "precison: 0.22920448834706647\n",
      "recall: 0.19579390358262141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MaciejGielerts176137\\miniconda3\\envs\\tfdml_plugin\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "X, y = train_data , y_train\n",
    "clf.fit(X, y)\n",
    "y_pred = clf.predict(test_data)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "prec = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(f'accuracy: {acc}\\nf1: {f1}\\nprecison: {prec}\\nrecall: {recall}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MaciejGielerts176137\\AppData\\Local\\Temp\\ipykernel_15076\\3734692154.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf = RandomForestClassifier(n_estimators = 50, random_state = 4235).fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.23581560283687944\n",
      "f1: 0.22429907811307742\n",
      "precison: 0.24009306134756317\n",
      "recall: 0.23582699102276916\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators = 50, random_state = 4235).fit(X, y)\n",
    "y_pred = clf.predict(test_data)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "prec = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(f'accuracy: {acc}\\nf1: {f1}\\nprecison: {prec}\\nrecall: {recall}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lightgbm_model = LGBMClassifier(\n",
    "    boosting_type='gbdt',\n",
    "    min_child_weight=0.001,\n",
    "    max_depth=10\n",
    ")\n",
    "lightgbm_model.fit(X, y)\n",
    "y_pred=lightgbm_model.predict(test_data)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "prec = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(f'accuracy: {acc}\\nf1: {f1}\\nprecison: {prec}\\nrecall: {recall}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LightGBM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Następnie sprawdzono klasyfikację przy ograniczeniu do 10 klas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_example_img(label_to_find):\n",
    "    for _img, _label in zip(images,labels_history):\n",
    "        if _label == label_to_find:\n",
    "            plt.figure()\n",
    "            plt.title(_label)\n",
    "            plt.imshow(_img, cmap='gray')\n",
    "            plt.show()\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smaller_dataset(x, y, labels):\n",
    "    new_train_data = []\n",
    "    new_y = []\n",
    "    for x_d,y_d in zip(x,y):\n",
    "        if y_d in labels:\n",
    "            new_train_data.append(x_d)\n",
    "            new_y.append(y_d)\n",
    "            \n",
    "    return new_train_data, new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "size = 15\n",
    "\n",
    "labels = random.sample(range(1, 47), size)\n",
    "#labels = [5, 14]\n",
    "#labels = encoder.transform(['dotted', 'polka-dotted'])\n",
    "\n",
    "X, y = smaller_dataset(train_data, y_train, labels)\n",
    "X_test_new, y_test_new = smaller_dataset(test_data, y_test, labels)\n",
    "\n",
    "labels_strs = encoder.inverse_transform(labels)\n",
    "print(f'chosen classes:\\n{labels_strs}')\n",
    "for labels_str in labels_strs:\n",
    "    show_example_img(labels_str)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "clf.fit(X, y)\n",
    "y_pred = clf.predict(X_test_new)\n",
    "acc = accuracy_score(y_test_new, y_pred)\n",
    "f1 = f1_score(y_test_new, y_pred, average='macro')\n",
    "prec = precision_score(y_test_new, y_pred, average='macro')\n",
    "recall = recall_score(y_test_new, y_pred, average='macro')\n",
    "\n",
    "print(f'accuracy: {acc}\\nf1: {f1}\\nprecison: {prec}\\nrecall: {recall}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators = 50, random_state = 4235).fit(X, y)\n",
    "y_pred = clf.predict(X_test_new)\n",
    "acc = accuracy_score(y_test_new, y_pred)\n",
    "f1 = f1_score(y_test_new, y_pred, average='macro')\n",
    "prec = precision_score(y_test_new, y_pred, average='macro')\n",
    "recall = recall_score(y_test_new, y_pred, average='macro')\n",
    "\n",
    "print(f'accuracy: {acc}\\nf1: {f1}\\nprecison: {prec}\\nrecall: {recall}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightgbm_model = LGBMClassifier(\n",
    "    boosting_type='gbdt',\n",
    "    min_child_weight=0.001,\n",
    "    max_depth=10\n",
    ")\n",
    "lightgbm_model.fit(X, y)\n",
    "y_pred=lightgbm_model.predict(X_test_new)\n",
    "acc = accuracy_score(y_test_new, y_pred)\n",
    "f1 = f1_score(y_test_new, y_pred, average='macro')\n",
    "prec = precision_score(y_test_new, y_pred, average='macro')\n",
    "recall = recall_score(y_test_new, y_pred, average='macro')\n",
    "\n",
    "print(f'accuracy: {acc}\\nf1: {f1}\\nprecison: {prec}\\nrecall: {recall}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Na koniec przetestowano homogeniczność, kontrast, korelacja, odmienność"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WNIOSKI:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfdml_plugin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1012f203b04506b130291f052b899c30bc3a01caefe658dd9d81239637d641ad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
